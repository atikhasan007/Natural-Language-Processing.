{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3000c0",
   "metadata": {},
   "source": [
    "# One-Hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe83b79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['money gets money'],\n",
       "       ['people earn money'],\n",
       "       ['money make money']], dtype='<U17')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#example sentence 3 document\n",
    "sentences = [\n",
    "    \"money gets money\",\n",
    "    \"people earn money\",\n",
    "    \"money make money\"\n",
    "]\n",
    "\n",
    "\n",
    "#Reshape the data for OneHotEncoder\n",
    "sentences = np.array(sentences).reshape(-1,1)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd5ebb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize Onehotencoder\n",
    "\n",
    "#parameters Explanined\n",
    "#handle_unknown = 'ignore';Ensures that unseen during encoding won't raise an error\n",
    "#sparse=False:Converts the result to a dense  numpy array (default is a sparse matrix)\n",
    "#get_feature_names_out(): Return the names of the one-hot-encoded feature \n",
    "\n",
    "\n",
    "\n",
    "#Key differentce:\n",
    "#Dense = all value store \n",
    "#sparse = only non - zero value stored\n",
    "\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "#fit and transform the data \n",
    "one_hot_encoded = encoder.fit_transform(sentences)\n",
    "one_hot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c233036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentences_money gets money', 'sentences_money make money',\n",
       "       'sentences_people earn money'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature names (column names after encoding )\n",
    "# Correct feature names extraction\n",
    "features = encoder.get_feature_names_out(['sentences'])\n",
    "\n",
    "features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d4102d",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c01cee7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['money gets money', 'people earn money', 'money make money']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#sample text data (documents)\n",
    "sentences = [\n",
    "    \"money gets money\",\n",
    "    \"people earn money\",\n",
    "    \"money make money\"\n",
    "]\n",
    "\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38582af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 2, 0],\n",
       "       [1, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 2, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize CountVectorizer with multiple parameters\n",
    "#stop_words='english'  #Remove common English stop words\n",
    "\n",
    "#ngram_range=(1,2)  #use unigram and bigrams\n",
    "#max_df=0.85, #Ignore words that appear in more than 85% of the documents\n",
    "#min_df=2, #Ignore words that appear in fewer then 2 documents\n",
    "#max_features = 5 #only keep the top 5 feature \n",
    "\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "\n",
    "#fit teh model and transform the document into word vectors\n",
    "X = vectorizer.fit_transform(sentences)\n",
    "\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbfba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary with index\n",
      "{'money': 3, 'gets': 1, 'people': 4, 'earn': 0, 'make': 2}\n"
     ]
    }
   ],
   "source": [
    "#get feature names (vocabulary )\n",
    "print(\"\\nVocabulary with index\")\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc4a7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Names(Vocabulary):  \n",
      "['earn' 'gets' 'make' 'money' 'people']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFeature Names(Vocabulary):  \")\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f9507",
   "metadata": {},
   "source": [
    "# Bi-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dba39c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text':['money get money',\n",
    "           'People earn money'],\n",
    "    'label':[0,1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab87b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>money get money</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People earn money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text  label\n",
       "0    money get money      0\n",
       "1  People earn money      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ac2aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(2,2))\n",
    "X = cv.fit_transform(df['text'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82e1b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money get': 2, 'get money': 1, 'people earn': 3, 'earn money': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59e06be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0],\n",
       "       [1, 0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36309866",
   "metadata": {},
   "source": [
    "# Tri Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b75ef9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(3,3))\n",
    "X = cv.fit_transform(df['text'])\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbcd10e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money get money': 0, 'people earn money': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b004246",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f329893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text':['people are here','people are not here','people are lovely'],\n",
    "    'label':[0,1,1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63e55bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people are here</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people are not here</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people are lovely</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text  label\n",
       "0      people are here      0\n",
       "1  people are not here      1\n",
       "2    people are lovely      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884ec7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52284231, 0.67325467, 0.        , 0.        , 0.52284231],\n",
       "       [0.39148397, 0.50410689, 0.        , 0.66283998, 0.39148397],\n",
       "       [0.45329466, 0.        , 0.76749457, 0.        , 0.45329466]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62c88bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.28768207 1.69314718 1.69314718 1.        ]\n",
      "['are' 'here' 'lovely' 'not' 'people']\n"
     ]
    }
   ],
   "source": [
    "#show the IDF values (optional)\n",
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c040f0",
   "metadata": {},
   "source": [
    "# countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c22aa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "X = count_vectorizer.fit_transform(df['text']).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d4149ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed37708c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['are', 'here', 'lovely', 'not', 'people'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e958252b",
   "metadata": {},
   "source": [
    "# Hashing Vectorizer / hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "952d46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70710677 0.70710677 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.57735026 0.         0.57735026 0.         0.\n",
      "  0.         0.         0.57735026 0.        ]\n",
      " [0.57735026 0.57735026 0.         0.         0.         0.\n",
      "  0.         0.57735026 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Sample sentences\n",
    "sentences = [\n",
    "    \"I love cats\",\n",
    "    \"You love dogs\",\n",
    "    \"We hate cats\"]\n",
    "\n",
    "# Instantiate HashingVectorizer with correct parameters\n",
    "hash_vectorizer = HashingVectorizer(\n",
    "    n_features=10,           # Fixed-size feature space\n",
    "    alternate_sign=False,    # Only positive values\n",
    "    dtype='float32',         # Save memory\n",
    "    norm='l2',               # ✅ Corrected normalization ('l2')\n",
    "    binary=False             # Use frequency counts instead of binary\n",
    ")\n",
    "\n",
    "\n",
    "# binary=True → word আছে কি নেই (1/0)\n",
    "\n",
    "# binary=False → word কয়বার আছে সেটার উপর ভিত্তি করে weight হবে\n",
    "\n",
    "\n",
    "\n",
    "# Transform the documents into feature vectors\n",
    "X = hash_vectorizer.transform(sentences)\n",
    "\n",
    "# Show as array\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "085117a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2        3    4    5    6        7        8    9\n",
       "0  0.707107  0.707107  0.0  0.00000  0.0  0.0  0.0  0.00000  0.00000  0.0\n",
       "1  0.000000  0.577350  0.0  0.57735  0.0  0.0  0.0  0.00000  0.57735  0.0\n",
       "2  0.577350  0.577350  0.0  0.00000  0.0  0.0  0.0  0.57735  0.00000  0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array = X.toarray()\n",
    "\n",
    "#display the hashed matrix\n",
    "import pandas as pd\n",
    "hashed_df = pd.DataFrame(x_array)\n",
    "hashed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5b37c",
   "metadata": {},
   "source": [
    "# word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99f0ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/catpc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/catpc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27c60aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'cat',\n",
       " 'sat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'mat',\n",
       " 'alst',\n",
       " 'night',\n",
       " '.',\n",
       " 'dog',\n",
       " 'was',\n",
       " 'barking',\n",
       " '.',\n",
       " 'we',\n",
       " 'love',\n",
       " 'elephant']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step1: preprocessing the sentence\n",
    "sentence = \"The cat sat on the mat alst night. Dog was barking. We love elephant\"\n",
    "#tokenize the sentence into words\n",
    "tokens = word_tokenize(sentence.lower())\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc79aba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'cat',\n",
       "  'sat',\n",
       "  'on',\n",
       "  'the',\n",
       "  'mat',\n",
       "  'alst',\n",
       "  'night',\n",
       "  '.',\n",
       "  'dog',\n",
       "  'was',\n",
       "  'barking',\n",
       "  '.',\n",
       "  'we',\n",
       "  'love',\n",
       "  'elephant']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 2: prepare data for word2vec\n",
    "#word2vec expects a list of tokenized sentence in a list to make it a list of sentences\n",
    "data = [tokens] #wrapping the tokenized sentence in a list to make it a list of sentences\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b12c408b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "\n",
    "    sentences=data,\n",
    "    vector_size=100, #size of the word vectors\n",
    "    window=3, #context window size\n",
    "    min_count=1, #minimum frequency of words to be include\n",
    "    sg=0, #use skip-gram model 1:skip-gram 0:cbow\n",
    "    workers=4 ,#Number of threads for training\n",
    "    epochs=10 #number of training epochs\t১০ বার পুরো ডেটার উপর ট্রেইন চালানো হবে\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27073879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00950068,  0.00956214, -0.00777185, -0.00264673, -0.00490651,\n",
       "       -0.00496661, -0.00802442, -0.00778391, -0.00455399, -0.00127607,\n",
       "       -0.00510379,  0.00613985, -0.00951582, -0.00530847,  0.00943814,\n",
       "        0.00699138,  0.00767634,  0.00423415,  0.00050704, -0.00598122,\n",
       "        0.00601702,  0.00263518,  0.00769886,  0.00639328,  0.00794293,\n",
       "        0.0086571 , -0.00989551, -0.00675694,  0.00133846,  0.00644132,\n",
       "        0.00737569,  0.00551627,  0.00766028, -0.00512456,  0.00658289,\n",
       "       -0.00410673, -0.00905557,  0.00914286,  0.00133203, -0.0027597 ,\n",
       "       -0.00247625, -0.00422078,  0.00481319,  0.00439984, -0.00265365,\n",
       "       -0.00734112, -0.00356601, -0.00033689,  0.00609497, -0.00283757,\n",
       "       -0.00012009,  0.00087842, -0.00709647,  0.00206604, -0.00143448,\n",
       "        0.00280224,  0.00484309, -0.00135222, -0.00278072,  0.00773736,\n",
       "        0.00504629,  0.00671411,  0.00451808,  0.00866735,  0.00747494,\n",
       "       -0.00108131,  0.00874718,  0.00460043,  0.0054402 , -0.00138785,\n",
       "       -0.00204073, -0.00442423, -0.0085144 ,  0.00303855,  0.00888275,\n",
       "        0.00892016, -0.00194262,  0.00608605,  0.00377963, -0.00429393,\n",
       "        0.00204485, -0.00543925,  0.00820817,  0.0054324 ,  0.00318543,\n",
       "        0.00410148,  0.0086552 ,  0.00727283, -0.0008319 , -0.00707259,\n",
       "        0.00838019,  0.00723589,  0.00172999, -0.00134733, -0.00588936,\n",
       "       -0.00453253,  0.00864858, -0.00313549, -0.00633763,  0.00986873],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 4: Analyze the trained word2vec model\n",
    "#get the vector for a specific word\n",
    "\n",
    "word_vector = model.wv['cat'] #get the vector representation for 'cat'\n",
    "word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "baf67586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elephant', 0.25284403562545776),\n",
       " ('.', 0.13719037175178528),\n",
       " ('love', 0.0441255047917366),\n",
       " ('dog', 0.012817534618079662),\n",
       " ('barking', 0.006613576784729958)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find most similar words to a given word\n",
    "similar_words = model.wv.most_similar('cat',topn=5)\n",
    "similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05d843b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['cat','dog','elephant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c27c5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x707d3f77a950>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the model \n",
    "model.save(\"word2vec_model.model\")\n",
    "\n",
    "#load the model\n",
    "loaded_model = Word2Vec.load(\"word2vec_model.model\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc3022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
